<!DOCTYPE html>
<html lang="en">

<head>
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-160037171-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-160037171-1');
    </script>
    
    
    <!-- Non social metatags -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    
    
    
    <title>Support Vector Machine - SVM</title>
    
    
    












<!-- Place this data between the <head> tags of your website -->

<meta name="description" content="서포트 벡터머신에 대한 세미나를 준비했다." />



  <meta name="keywords" itemprop="categories" content="Machine Learning" />



<!-- Twitter Card data -->
<meta name="twitter:card" content="summary_large_image" />



<meta name="twitter:title" content="Support Vector Machine - SVM" />
<meta name="twitter:description" content="서포트 벡터머신에 대한 세미나를 준비했다." />



<!-- Twitter summary card with large image must be at least 280x150px -->

  <meta name="twitter:image:src" content="http://localhost:4000/thumbnail-jumbo.png" />
  <meta name="twitter:image" content="http://localhost:4000/thumbnail-jumbo.png" />

<meta name="twitter:url" content="http://localhost:4000//machine%20learning/2020/05/07/SVM.html" />

<!-- Open Graph data -->
<meta property="og:title" content="Support Vector Machine - SVM" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:4000//machine%20learning/2020/05/07/SVM.html" />


  <meta property="og:image" content="http://localhost:4000/thumbnail-jumbo.png" />

<meta property="og:description" content="서포트 벡터머신에 대한 세미나를 준비했다." />
<meta property="og:site_name" content="현우의 공유메모장" />


<meta property="og:locale" content="" />


  <meta property="article:published_time" content="2020-05-07T00:00:00+09:00" />




  





  
    <meta property="article:tag" content="Machine Learning" />
  




    
    
    <link rel="canonical" href="http://localhost:4000/machine%20learning/2020/05/07/SVM.html">
    
    
    
    <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
    
    <meta name="robots" content="noarchive">
    
    <!-- <link rel="alternate" media="only screen and (max-width: 640px)" href="">
        <link rel="alternate" media="handheld" href=""> -->
        
        
        <link rel="stylesheet" href="http://localhost:4000/assets/css/style.css?v=">
    </head>
    <body>
        
        <header class="site-header" role="banner">

  <div class="wrapper">
    
    

    
      <a class="site-title" href="http://localhost:4000/">현우의 공유메모장</a>
    

    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"></path>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"></path>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
              
                <a class="page-link" href="http://localhost:4000/category.html">카테고리</a>
              
            
          
            
            
              
                <a class="page-link" href="http://localhost:4000/about.html">About</a>
              
            
          
        </div>
      </nav>
    
  </div>
</header>

        
        
        
        
        
        <section class="page-header">
            <h1 class="project-name">Support Vector Machine - SVM</h1>
            <h2 class="project-tagline"></h2>
            
            <!-- Post tagline -->
            
            <h2 class="project-date">
                <time datetime="2020-05-07T00:00:00+09:00" itemprop="datePublished">
                    
                    May 7, 2020
                </time>
                
                
                • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">optboy</span></span>
                
            </h2>
            
            <!-- End: Post tagline -->
        </section>
        
        <section class="main-content">
            
            <article itemscope itemtype="http://schema.org/BlogPosting">

  <!-- <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Support Vector Machine - SVM</h1>
    <p class="post-meta">
      <time datetime="2020-05-07T00:00:00+09:00" itemprop="datePublished">
        
        May 7, 2020
      </time>
      
        • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">optboy</span></span>
      </p>
  </header> -->

  <div itemprop="articleBody">
    <p>서포트 벡터머신에 대한 세미나를 준비했다.</p>

<ul>
  <li>support vector machine?
    <ul>
      <li>고차원 데이터 분류문제에 좋은 성능을 보인다.</li>
      <li>이차방정식 문제로 formulation을 한다.</li>
      <li>training data에 대해서 성능이 좋아야 하는데, 너무 좋으면 overfitting 문제가 생긴다. testing error에 대해서도 성능이 좋아햐 한다. 이걸 generalization ability라고 한다.</li>
      <li>근데 training ability와 generalization ability간에는 상충관계가 존재한다.</li>
      <li>하지만 SVM은 training error를 줄이면 testing error도 줄어드는 모델을 만들 수 있다.</li>
      <li>
        <p>SVM은 통계에 근거해 탄탄히 발전함.</p>
      </li>
      <li>분류문제를 다룬다. (two-class)</li>
      <li>3차원 공간에서 hyperplane을 찾는 것.
        <ul>
          <li>식은 <script type="math/tex">w^Tx + b = 0</script>이다.</li>
          <li>w:nominal vector of the hyperplane, b: bias</li>
          <li>
<script type="math/tex">w, b</script>를 찾아야 한다.</li>
        </ul>
      </li>
      <li>어떻게 찾는가? 두 클래스를 나누는 hyperplane은 무수히 많다.</li>
      <li>가장 좋은걸 찾아야 하는데, 그 기준은 무엇인가.</li>
      <li>SVM에서 추구하는 건 margin이라는 개념.
        <ul>
          <li>training에서 margin을 최대화하는 hyperplane을 찾자. 그러면 generalization error은 줄어든다.</li>
          <li>그러면 예측 성능도 좋아지는 것이다.</li>
        </ul>
      </li>
      <li>그러면 margin이 뭐냐?
        <ul>
          <li>두 클래스가 있고, hyperplane이 있을 때, 각 클래스에서 가장 가까운 관측치에 대한 거리를 margin이라고 한다.</li>
          <li>
            <p>이 margin은 w(기울기)로 표현이 가능하다.</p>
          </li>
          <li>한 클래스를 +, 한 클래스를 -라고 했을 때, + plane은 정확히 y값이 +1인 값을 갖는 x들이 +plane에 있는 거고, -1을 갖는 x들은 -plane에 있는 것. 1보다 크거나 같은 녀석들이 + 클래스에 속하고, -1보다 작거나 같은 녀석들이 -클래스에 속하게 된다.</li>
          <li>이 마진을 최대화하는 hyper plane을 찾는 것. 2차원이라면 직선이 된다.</li>
          <li>+에 있는 점은 -에 있는 점을 w방향으로 평행이동한 것과 같다.</li>
        </ul>
      </li>
      <li>수학적으로 margin을 알아보자.
        <ul>
          <li>결국 <script type="math/tex">\lambda = \frac{2}{w^tw}</script>임.</li>
          <li>p norm에 대해서 알아야 함. -&gt; L2 norm은 유클리디안 거리임.</li>
          <li>이런저런 유도를 통해 margin = <script type="math/tex">\frac{2}{\lVert w \rVert_2} = \frac{2}{\sqrt{w^tw}}</script>가 된다.</li>
          <li>이걸 maximize해야하는데, 그 역수를 minimize해도 된다.</li>
          <li>
            <p>근데 L2 norm은 제곱근이 있어서 제곱을 시켜서 목적함수를 바꿔줄 수도 있다.</p>
          </li>
          <li>이거 convex optimization problem으로 풀 수 있다.</li>
          <li>목적식과 제약식이 있음. 제약이 margin을 1보다는 크게 하는 것임.</li>
          <li>목적식이 2차함수이기 때문에 quadratic programming(QP)임. 근데 QP는 convex optimization임.</li>
          <li>convex는 global optimal solution을 쉽게 찾을 수 있다.</li>
        </ul>
      </li>
      <li>이걸 Lagrangian multiplier으로 하나의 목적식으로 만들어 줄 수 있다.</li>
      <li>이 목적식을 최소로 하는 문제를 풀면 된다. 미분하면 된다.</li>
      <li>그러면 w에 대한 식이 구해지고, y와 알파의 관계를 알 수 있음.</li>
      <li>이것도 primal 목적식에 넣는다.</li>
      <li>이것저것해서 최종적으로 알파에 대한 dual문제를 만들 수 있음.</li>
      <li>
        <p>목적식을 최대화 하는 알파를 찾는다.</p>
      </li>
      <li>dual문제가 최적해가 되기 위한 조건 - KKT조건
        <ul>
          <li>primal도 얻고, dual도 얻었으면 이러한 조건을 얻어야 한다.
            <ol>
              <li>stationarity : 미분해서 0이 되는 지점이 존재해야 한다.</li>
              <li>primal feasibilty</li>
              <li>dual feasibility</li>
              <li>complementary slackness : <script type="math/tex">a_i(y_i(w^tx_i+b)-1) = 0</script>
</li>
            </ol>
          </li>
        </ul>
      </li>
      <li>complementary slackness
        <ul>
          <li>알파가 0보다 클 때 뒤에 있는게 0이어야 함. =&gt; <script type="math/tex">y_i(w^tx_i+b) = 1</script>이어야 함.
            <ul>
              <li>이 경우가 plus-plane이나 minus-plane위에 있는 것 -&gt; 이게 support vector임.</li>
            </ul>
          </li>
          <li>알파가 0이면 뒤에 있는 애들이 0이 아니어도 된다. 이게 support vector 뒤에 있는 애들임.</li>
          <li>margin을 구할 때 사용하는 것들은 support vector에 해당하는 것들이다.</li>
        </ul>
      </li>
      <li>x가 support vector인 경우만 알파가 0보다 크거나 같으므로, support vector만 이용해서 Hyper plane을 구할 수 있다.
        <ul>
          <li>sparse representation</li>
        </ul>
      </li>
      <li>
        <p>이걸로 w랑 b구한다.</p>
      </li>
      <li>새로운 데이터가 optimal separating hyperplane보다 밑에 있으면 -1, 위에 있으면 1로 예측하여 class를 부여한다.</li>
    </ul>
  </li>
  <li>선형 분리 불가능한 경우의 선형 SVM -&gt; soft margin SVM
    <ul>
      <li>
        <p>선형분리 가능하면 위에 설명한 것 -&gt; hard margin SVM</p>
      </li>
      <li>완벽하게 나뉘지 못하는 경우가 생긴다.</li>
      <li>이럴때는 hard margin SVM과 유사한 방법을 쓰나, error을 허용한다.</li>
      <li>정규화에서 regularigation처럼 목적함수 뒤에 에러(slack variable)를 붙여준다.</li>
      <li>여기서 상수 C를 붙여서 penalty를 최대한 억제한다.</li>
      <li>C값을 크게하면 에러를 허용하지 않지만, overfit될 가능성이 있다.</li>
      <li>
        <p>C값을 작게하면 에러를 허용하게 되고, underfit될 가능성이 생긴다.</p>
      </li>
      <li>여기서도 lagrangian relaxation을 하고, 목적함수 미분해서 0나오는 값을 찾는다.</li>
      <li>아까랑 똑같은데 크사이 하나 더 생김. 이에 대한 식을 하나 얻을 수 있다. 총 3개 얻음.</li>
      <li>
        <p>전개해서 포뮬레이션 만들면 알파가 C보다 작거나 같아야하는 제약만 더해짐.</p>
      </li>
      <li>역시 KKT condition</li>
      <li>…</li>
    </ul>
  </li>
  <li>비선형 SVM, kernal method
    <ul>
      <li>기본 아이디어는 관측치 x를 더 높은 차원으로 변환시켜 분류한다.</li>
      <li>x들을 어떤 함수에 통과시켜서 z를 얻는다.</li>
      <li>p차원에서 q차원으로 바꿈. q가 훨씬 큼. 3차원에서 10차원 정도로 올려버림. 이렇게 바꾸고 선형으로 푼다.</li>
      <li>
        <p>original space에서 feature space로 바꾸는 것임. 이러면 더 쉽게 계산할 수 있음.</p>
      </li>
      <li>SVM lagrangian dual 포뮬레이션 보면 x에 대한 inner project(내적)이 있는데, 이걸 <script type="math/tex">\phi</script>를 이용해서 데이터를 변환한 후 한다. 내적은 element들끼리 곱해서 더하는 것.</li>
      <li>
        <p><script type="math/tex">\phi</script>의 형태를 알아야 하는데, 그걸 몰라도 되는게, kernal function.</p>
      </li>
      <li>
        <p>예제</p>
      </li>
      <li>
        <p>이런 저런 kernal function들이 있다.</p>
      </li>
      <li>예제.</li>
    </ul>
  </li>
  <li>비선형 SVM</li>
</ul>

<h4 id="참고">참고</h4>

<ul>
  <li><a href="https://ko.wikipedia.org/wiki" target="_blank" rel="noopener noreferrer nofollow">wekipedia</a></li>
  <li><a href="https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/" target="_blank" rel="noopener noreferrer nofollow">ratsgo’s blog</a></li>
</ul>

  </div>

  
</article>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://https-optboy-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener noreferrer nofollow">comments powered by Disqus.</a>
</noscript>
                            



            
            <footer class="site-footer">
                <!-- SVG icons from https://iconmonstr.com -->
                
                <!-- Github icon -->
                <span class="my-span-icon">
                    <a href="" aria-label="'s GitHub" title="'s GitHub">
                        <svg class="my-svg-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>
                    </a>
                </span>
                
                <!-- Twitter icon -->
                <span class="my-span-icon">
                    <a href="https://twitter.com/" aria-label="'s Twitter" title="'s Twitter" target="_blank" rel="noopener noreferrer nofollow">
                        <svg class="my-svg-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24"><path d="M12 0c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm6.066 9.645c.183 4.04-2.83 8.544-8.164 8.544-1.622 0-3.131-.476-4.402-1.291 1.524.18 3.045-.244 4.252-1.189-1.256-.023-2.317-.854-2.684-1.995.451.086.895.061 1.298-.049-1.381-.278-2.335-1.522-2.304-2.853.388.215.83.344 1.301.359-1.279-.855-1.641-2.544-.889-3.835 1.416 1.738 3.533 2.881 5.92 3.001-.419-1.796.944-3.527 2.799-3.527.825 0 1.572.349 2.096.907.654-.128 1.27-.368 1.824-.697-.215.671-.67 1.233-1.263 1.589.581-.07 1.135-.224 1.649-.453-.384.578-.87 1.084-1.433 1.489z"></path></svg>
                    </a>
                </span>
                
                <!-- RSS icon -->
                
                
                <!-- Contact icon -->
                
                
                
            </footer>
        </section>
        
        <script>
            var menu = document.querySelector("nav.site-nav");
            var checkbox = document.getElementById("nav-trigger");
            
            // close menu if click outside menu
            document.addEventListener("click", function(e) {
                if (menu != e.target &&
                        !isDescendant(menu, e.target)) {
                    checkbox.checked = false;
                }
            }, false);
            
            function isDescendant(parent, child) {
                var node = child.parentNode;
                while (node != null) {
                    if (node == parent) {
                        return true;
                    }
                    node = node.parentNode;
                }
                return false;
            }  
        </script>
        
    </body>
    </html>
    